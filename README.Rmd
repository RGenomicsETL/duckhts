---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```
# DuckHTS

A [DuckDB](https://duckdb.org/) extension (see the [DuckDB Extension API](https://duckdb.org/docs/extensions/overview)) for reading high-throughput sequencing (HTS)
file formats using [htslib](https://github.com/samtools/htslib).

Query VCF, BCF, BAM, CRAM, FASTA, FASTQ, GTF, GFF, and tabix-indexed files directly using SQL.

Note: MSVC builds (windows_amd64/windows_arm64) are not supported. Use MinGW/RTools for Windows.

## Functions

| Function | Description | Schema |
|---|---|---|
| `read_bcf(path, [region, tidy_format])` | Read VCF/BCF files | CHROM, POS, ID, REF, ALT, QUAL, FILTER, INFO_*, FORMAT_* |
| `read_bam(path, [region, reference])` | Read SAM/BAM/CRAM files | QNAME, FLAG, RNAME, POS, MAPQ, CIGAR, RNEXT, PNEXT, TLEN, SEQ, QUAL, READ_GROUP_ID, SAMPLE_ID |
| `read_fasta(path)` | Read FASTA files | NAME, DESCRIPTION, SEQUENCE |
| `read_fastq(path, [mate_path, interleaved])` | Read FASTQ files | NAME, DESCRIPTION, SEQUENCE, QUALITY (+ MATE, PAIR_ID when paired/interleaved) |
| `read_gff(path, [region, attributes_map])` | Read GFF3 files | seqname, source, feature, start, end, score, strand, frame, attributes (+ attributes_map MAP when enabled) |
| `read_gtf(path, [region, attributes_map])` | Read GTF files | seqname, source, feature, start, end, score, strand, frame, attributes (+ attributes_map MAP when enabled) |
| `read_tabix(path, [region])` | Read any tabix-indexed file | column0, column1, … (auto-detected) |

## Examples

```sql
LOAD 'duckhts';

-- Read a VCF file (tidy FORMAT columns)
SELECT CHROM, POS, REF, ALT, QUAL, FORMAT_GT
FROM read_bcf('test/data/formatcols.vcf.gz', tidy_format := true)
WHERE CHROM = '1' AND POS > 1000000;

-- Region query on an indexed VCF (requires .tbi or .csi index)
SELECT * FROM read_bcf('test/data/vcf_file.bcf', region := '1:3000150-3000151');

-- VEP annotations (CSQ/BCSQ/ANN when present)
SELECT CHROM, POS, VEP_Allele, VEP_Consequence
FROM read_bcf('test/data/test_vep.vcf')
LIMIT 1;

-- Convert a VCF slice to Parquet using DuckDB COPY
COPY (
  SELECT *
  FROM read_bcf('test/data/vcf_file.bcf', region := '1:3000000-3000500')
) TO 'variants.parquet' (FORMAT PARQUET);

-- Read a BAM file
SELECT QNAME, FLAG, RNAME, POS, MAPQ, CIGAR, READ_GROUP_ID, SAMPLE_ID
FROM read_bam('test/data/range.bam')
WHERE FLAG & 4 = 0;  -- mapped reads only

-- Region query on an indexed BAM
SELECT count(*) FROM read_bam('test/data/range.bam', region := 'CHROMOSOME_I:1-1000');

-- CRAM with explicit reference
SELECT count(*) FROM read_bam('test/data/range.cram', reference := 'test/data/ce.fa');

-- Read FASTA sequences
SELECT NAME, length(SEQUENCE) as seq_length
FROM read_fasta('test/data/ce.fa');

-- Read FASTQ and compute average quality
SELECT NAME, length(SEQUENCE) as read_length
FROM read_fastq('test/data/r1.fq');

-- Paired FASTQ (mate_path)
SELECT NAME, MATE, PAIR_ID
FROM read_fastq('test/data/r1.fq', mate_path := 'test/data/r2.fq');

-- Interleaved FASTQ
SELECT NAME, MATE, PAIR_ID
FROM read_fastq('test/data/interleaved.fq', interleaved := true);

-- Read GFF3 annotations
SELECT seqname, feature, start, "end", attributes, attributes_map
FROM read_gff('test/data/gff_file.gff.gz', attributes_map := true)
WHERE feature = 'gene';

-- Read a tabix-indexed BED file
SELECT * FROM read_tabix('test/data/gff_file.gff.gz', region := 'X:2934816-2935190');
```

## Building

### Environment setup

Run the one-time configure step to create the Python venv and detect platform settings:

```bash
make configure
```

Note: MSVC builds (windows_amd64/windows_arm64) are not supported. Use MinGW/RTools for Windows.

### Prerequisites

- C compiler (GCC or Clang)
- CMake ≥ 3.5
- Make
- Python 3 + venv
- Git
- [htslib](https://github.com/samtools/htslib) build dependencies: zlib, libbz2, liblzma, libdeflate, libcurl, libcrypto (OpenSSL)

On Debian/Ubuntu:

```bash
sudo apt install build-essential cmake python3 python3-venv git \
    zlib1g-dev libbz2-dev liblzma-dev libdeflate-dev libcurl4-openssl-dev libssl-dev
```

On macOS:

```bash
brew install cmake htslib xz libdeflate
```

### Vendor [htslib](https://github.com/samtools/htslib)

```bash
./scripts/vendor_htslib.sh
```

This downloads and verifies [htslib](https://github.com/samtools/htslib) 1.23 into `third_party/htslib/`.

### Build

```bash
make configure    # one-time setup (Python venv, platform detection)
make release      # build optimised extension
```

The build runs [htslib](https://github.com/samtools/htslib)'s Makefile (`make lib-static`) in-tree.

The extension binary is written to `build/release/duckhts.duckdb_extension`.

### Debug build

```bash
make debug
```

## Loading

```sql
-- Unsigned extensions must be loaded with -unsigned flag:
-- duckdb -unsigned

LOAD '/path/to/duckhts.duckdb_extension';
```

## Testing

SQL tests live in `test/sql/` using [DuckDB](https://duckdb.org/)'s SQLLogicTest format.

Before running tests for the first time, prepare the indexed test data:

```bash
./test/scripts/prepare_test_data.sh   # requires samtools, bcftools, bgzip, tabix
```

This copies files from the vendored [htslib](https://github.com/samtools/htslib) test suite into `test/data/` and
builds the required indexes (BAI, CSI, TBI, FAI) so region queries work.

Then run:

```bash
make test_release
```

## R demo

The R package lives under r/Rduckhts and provides helpers to load the extension
and create [DuckDB](https://duckdb.org/) tables from HTS files. See its README for R-specific usage:
[r/Rduckhts/README.Rmd](r/Rduckhts/README.Rmd).

```{r eval=TRUE}
library(DBI)
library(duckdb)

drv <- duckdb::duckdb(config = list(allow_unsigned_extensions = "true"))
con <- dbConnect(drv, dbdir = ":memory:")
ext_path <- normalizePath("build/release/duckhts.duckdb_extension", mustWork = FALSE)
dbExecute(con, sprintf("LOAD '%s'", ext_path))

dbGetQuery(con, "
  SELECT *
  FROM read_bcf('test/data/formatcols.vcf.gz', tidy_format := true)
  LIMIT 5
")

parquet_path <- tempfile(fileext = ".parquet")
dbExecute(con, sprintf(
  "COPY (SELECT * FROM read_bcf('test/data/formatcols.vcf.gz', tidy_format := true)) TO '%s' (FORMAT PARQUET)",
  parquet_path
))
file.exists(parquet_path)

dbGetQuery(con, "
  SELECT NAME, SEQUENCE, QUALITY, MATE, PAIR_ID
  FROM read_fastq('test/data/r1.fq', mate_path := 'test/data/r2.fq')
  LIMIT 5
")

dbGetQuery(con, "
  SELECT QNAME, RNAME, POS, READ_GROUP_ID, SAMPLE_ID
  FROM read_bam('test/data/rg.sam.gz')
  LIMIT 5
")

dbGetQuery(con, "
  SELECT seqname, feature, start, \"end\", attributes_map
  FROM read_gff('test/data/gff_file.gff.gz', attributes_map := true)
  WHERE feature = 'gene'
  LIMIT 5
")

dbDisconnect(con, shutdown = TRUE)
```

Rendering this document requires a built extension at `build/release/duckhts.duckdb_extension`.

## Project Structure

```
src/
  duckhts.c          # Extension entry point
  bcf_reader.c       # VCF/BCF reader (read_bcf)
  bam_reader.c       # SAM/BAM/CRAM reader (read_bam)
  seq_reader.c       # FASTA/FASTQ reader (read_fasta, read_fastq)
  tabix_reader.c     # Tabix/GTF/GFF reader (read_tabix, read_gtf, read_gff)
  vep_parser.c       # VEP/CSQ annotation parser
  include/
    vcf_types.h
    vep_parser.h
third_party/
  htslib/            # Vendored htslib 1.23 (built automatically)
test/
  sql/               # SQL logic tests
duckdb_capi/
  duckdb.h           # DuckDB C API headers
  duckdb_extension.h
```

## References

- DuckDB: https://duckdb.org/
- DuckDB Extension API: https://duckdb.org/docs/extensions/overview
- DuckDB extension template (C): https://github.com/duckdb/extension-template-c
- htslib: https://github.com/samtools/htslib
- RBCFTools: https://github.com/RGenomicsETL/RBCFTools

## License

MIT
